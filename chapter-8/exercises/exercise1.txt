We discussed using the expression sizeof(a) / sizeof(a[0]) to calculate the number of elements in an array. 
The expression sizeof(a) / sizeof(t), where t is the type of a's elements would also work, but it's considered an inferior technique. Why?

If the array's data type changes then we would also have to change t, where the first expression will always work, even if we decide to change the type of the array.
I also believe it is easier to read than the second expression.